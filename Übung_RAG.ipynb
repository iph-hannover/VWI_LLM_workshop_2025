{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68fcc151",
   "metadata": {},
   "source": [
    "# RAG Explore: Interaktives Experimentieren mit Retrieval-Augmented Generation\n",
    "\n",
    "In diesem Notebook kannst du alle wichtigen Parameter einer RAG-Pipeline mit LangChain selbst anpassen und die Auswirkungen direkt beobachten.\n",
    "\n",
    "**Was kannst du hier explorieren?**\n",
    "- Chunkgröße & Overlap\n",
    "- Prompt-Formulierung\n",
    "- Anzahl der Top-k Chunks für das Retrieval\n",
    "\n",
    "**Ziel:**\n",
    "Verstehe, wie sich die Parameter auf die Qualität der Antworten und die Auswahl der Chunks auswirken. Probiere verschiedene Kombinationen aus und diskutiere die Ergebnisse!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain_community langchain_openai openai pypdf python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import textwrap\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "import chromadb\n",
    "\n",
    "# API-Key aus .env laden\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5bd355",
   "metadata": {},
   "source": [
    "## 1. PDFs einlesen\n",
    "\n",
    "Hier werden die drei Lieferantenberichte geladen und als Dokumente (je Seite) gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec14858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Seiten insgesamt geladen.\n"
     ]
    }
   ],
   "source": [
    "pdf_dir = \"data/PDFs\"\n",
    "all_docs = []\n",
    "\n",
    "for fn in os.listdir(pdf_dir):\n",
    "    if not fn.endswith(\".pdf\"): continue\n",
    "    loader = PyPDFLoader(os.path.join(pdf_dir, fn))\n",
    "    docs = loader.load()\n",
    "    supplier_name = fn.replace(\".pdf\", \"\")\n",
    "    for d in docs:\n",
    "        d.metadata[\"source_file\"] = fn\n",
    "        d.metadata[\"supplier\"] = supplier_name\n",
    "    all_docs.extend(docs)\n",
    "\n",
    "print(f\"{len(all_docs)} Seiten aus PDF-Dateien geladen.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f98922",
   "metadata": {},
   "source": [
    "## 2. Chunking – **Experimentier-Bereich!**\n",
    "\n",
    "Ändere hier Chunkgröße und Overlap und sieh, wie sich die Chunks ändern!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Chunks (Größe: 800, Overlap: 100)\n"
     ]
    }
   ],
   "source": [
    "# <<< Hier Chunkgröße/Overlap anpassen >>>\n",
    "chunk_size = 800      # z.B. 500, 800, 1200\n",
    "chunk_overlap = 100   # z.B. 50, 100, 200\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \", \"\"]\n",
    ")\n",
    "split_docs = text_splitter.split_documents(all_docs)\n",
    "\n",
    "chunk_lens = [len(d.page_content.split()) for d in split_docs]\n",
    "plt.hist(chunk_lens, bins=20, color='royalblue')\n",
    "plt.title(\"Wortlängen der Chunks\")\n",
    "plt.xlabel(\"Wortanzahl pro Chunk\")\n",
    "plt.ylabel(\"Anzahl Chunks\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"{len(split_docs)} Chunks (Größe: {chunk_size}, Overlap: {chunk_overlap})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc62e934",
   "metadata": {},
   "source": [
    "## 3. Embeddings und Vektorstore (Chroma)\n",
    "\n",
    "Wandle die Chunks in Embeddings um und speichere sie im Vektorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "client = chromadb.PersistentClient(path=\"db/\")\n",
    "if \"chunks\" in [c.name for c in client.list_collections()]:\n",
    "    client.delete_collection(\"chunks\")\n",
    "\n",
    "vectordb = Chroma(client=client, collection_name=\"chunks\",\n",
    "                   embedding_function=embeddings)\n",
    "vectordb.add_documents(split_docs)\n",
    "print(\"✅ Vektorstore erstellt (Duplikate gelöscht)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5d793",
   "metadata": {},
   "source": [
    "## 4. Retriever & Chatbot – **Experimentier-Bereich!**\n",
    "\n",
    "Passe hier top_k (wie viele relevante Chunks?) an und formuliere den Prompt beliebig um!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<< Hier top_k und Prompt anpassen >>>\n",
    "top_k = 4\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"Du bist ein Rechercheassistent für Lieferantenberichte. Antworte nur auf Basis des Kontexts und fasse präzise zusammen.\n",
    "Kontext:\n",
    "{context}\n",
    "Frage: {question}\n",
    "Antwort:\"\"\"\n",
    ")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": top_k})\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a08fb",
   "metadata": {},
   "source": [
    "## 5. Eigene Frage testen – **Experimentier-Bereich!**\n",
    "\n",
    "Gib hier deine eigene Frage ein!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b49042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frage: Wie geht Sparfuchs GmbH mit Reklamationen um?\n",
      "Antwort: Der Bericht enthält keine spezifischen Informationen darüber, wie Sparfuchs GmbH mit Reklamationen umgeht. Es wird jedoch erwähnt, dass die Zusammenarbeit mit Sparfuchs von Herausforderungen in Bezug auf Qualität und Transparenz geprägt ist, was darauf hindeutet, dass es möglicherweise Schwierigkeiten bei der Bearbeitung von Reklamationen geben könnte. Weitere Details zu diesem Thema sind im Kontext nicht vorhanden.\n"
     ]
    }
   ],
   "source": [
    "frage = \"Wie geht Sparfuchs GmbH mit Reklamationen um?\"  # Beliebige Frage eintragen\n",
    "result = qa_chain({\"query\": frage})\n",
    "print(\"Frage:\", frage)\n",
    "print(\"Antwort:\", result[\"result\"])\n",
    "\n",
    "print(f\"\\nTop-{top_k} relevante Chunks:\")\n",
    "for idx, doc in enumerate(result[\"source_documents\"][:top_k], 1):\n",
    "    sup = doc.metadata.get(\"supplier\", \"unbekannt\")\n",
    "    src = doc.metadata.get(\"source_file\", \"unbekannt\")\n",
    "    print(f\"[{idx}] {sup} ({src}):\")\n",
    "    print(textwrap.shorten(doc.page_content.strip(), width=300, placeholder=\"...\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2256769",
   "metadata": {},
   "outputs": [],
   "source": [
    "frage = \"Wie geht Sparfuchs GmbH mit Reklamationen um?\" # <<< Hier beliebige Frage stellen!\n",
    "result = qa_chain({\"query\": frage})\n",
    "print(\"Frage:\", frage)\n",
    "print(\"Antwort:\", result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "frage = \"Wie geht Sparfuchs GmbH mit Reklamationen um?\" # <<< Hier beliebige Frage stellen!\n",
    "result = qa_chain({\"query\": frage})\n",
    "print(\"Frage:\", frage)\n",
    "print(\"Antwort:\", result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68205844",
   "metadata": {},
   "outputs": [],
   "source": [
    "frage = \"Wie geht Sparfuchs GmbH mit Reklamationen um?\" # <<< Hier beliebige Frage stellen!\n",
    "result = qa_chain({\"query\": frage})\n",
    "print(\"Frage:\", frage)\n",
    "print(\"Antwort:\", result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc735dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "frage = \"Wie geht Sparfuchs GmbH mit Reklamationen um?\" # <<< Hier beliebige Frage stellen!\n",
    "result = qa_chain({\"query\": frage})\n",
    "print(\"Frage:\", frage)\n",
    "print(\"Antwort:\", result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567b3dfb",
   "metadata": {},
   "source": [
    "## 6. Aufgaben/Tipps\n",
    "\n",
    "- Ändere die Chunkgröße und vergleiche die Resultate.\n",
    "- Variiere top_k.\n",
    "- Passe den Prompt kreativ an!\n",
    "- Teste verschiedene eigene Fragen.\n",
    "- Diskutiere mit anderen, welche Konfiguration am besten ist!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
